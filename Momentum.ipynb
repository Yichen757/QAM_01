{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63bb67b-8fc6-4c25-8a90-313094a12b02",
   "metadata": {},
   "source": [
    "# Momentum 策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1fccc-e5bf-4547-896b-f2ec848c749f",
   "metadata": {},
   "source": [
    "本專案旨在系統性地重建並驗證美股市場中動能投資組合 (Momentum Portfolios) 的表現與穩健性。透過使用 CRSP 股票資料、Fama-French 因子檔以及外部提供的 decile 報酬率檔 (DM 與 KRF)，本專案執行以下主要步驟：\n",
    "\n",
    "1. 資料前處理與清理\n",
    "\n",
    "    對 CRSP 股票資料進行篩選（只留普通股與主要交易所股票），合併正常報酬與退市報酬，確保資料正確性。\n",
    "    \n",
    "    計算 lag 市值，避免 look-ahead bias。\n",
    "\n",
    "2. 動能因子計算\n",
    "\n",
    "    以 12-2 月累積報酬作為 Ranking Return，根據全市場 (DM) 與 NYSE-only (KRF) 分組基準，將股票分成 10 個 decile。\n",
    "\n",
    "3. 投資組合報酬計算\n",
    "\n",
    "    根據 lagged 市值加權，計算每個 decile 的每月報酬率。\n",
    "    \n",
    "    計算動能投資組合 (WML: Winner-Minus-Loser) 報酬，捕捉動能異象的 alpha。\n",
    "\n",
    "4. 績效與穩健性驗證\n",
    "\n",
    "    與 Daniel & Moskowitz、Kenneth R. French 官方 decile 報酬率檔案進行相關性檢驗。\n",
    "    \n",
    "    輸出 decile & WML 投資組合的年化報酬、波動度、Sharpe Ratio、偏態與與官方資料的相關性。\n",
    "\n",
    "5. 視覺化與結論\n",
    "\n",
    "    繪製 1929-2024 & 2010-2024 年間的累積 log 報酬率圖，直觀比較動能策略在不同時期的表現。\n",
    "    \n",
    "    提供研究洞察與未來可能的市場 regime shift 影響。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b6b30fe-3a22-4c9d-bc5a-b3e15dac0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c60f0e87-be5d-4fe4-9b27-0e7fccd9eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對於原始的 CRSP 股票資料，進行初步的資料清理與格式標準化。\n",
    "def clean_CRSP_Stocks(df: pd.DataFrame):\n",
    "    # Casting date to datetime\n",
    "    df_clean = df.copy()\n",
    "    df_clean.date = pd.to_datetime(df_clean.date, format='%Y-%m-%d')\n",
    "    df_clean.EXCHCD = df_clean.loc[:, \"EXCHCD\"].astype(\"int64\")\n",
    "\n",
    "    # Filterling only common share class (10, 11) and  major exchange(1, 2, 3)\n",
    "    df_clean = df_clean[df_clean.EXCHCD.isin([1, 2, 3]) & df_clean.SHRCD.isin([10, 11])]\n",
    "    \n",
    "    # replace all non-numeric (including nan) value to zero\n",
    "    df_clean.loc[:, \"valid_ret\"] = ~(df_clean.RET.isna() & df_clean.DLRET.isna())\n",
    "    \n",
    "    df_clean.DLRET = df_clean.DLRET.fillna(0)\n",
    "    df_clean.DLRET = df_clean.DLRET.replace([\"S\", \"T\", \"A\", \"P\"], 0).astype(float)\n",
    "    df_clean.RET = df_clean.RET.fillna(0)\n",
    "    df_clean.RET = df_clean.RET.replace([\"A\", \"B\", \"C\", \"D\", \"E\", \".\"], 0).astype(float)\n",
    "    \n",
    "    # Merging Delisting and Holding Returns\n",
    "    df_clean.RET = (1+df_clean.RET) * (1+df_clean.DLRET) - 1\n",
    "\n",
    "    # Sorting the dataframe by date and premno\n",
    "    df_clean.sort_values([\"date\", \"PERMNO\"], ignore_index=True, inplace=True)\n",
    "    df_clean.drop([\"SHRCD\", \"DLRET\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Change datatype for EXCHCD\n",
    "    df_clean.loc[:, \"EXCHCD\"] = df_clean.loc[:, \"EXCHCD\"].astype(np.int8)\n",
    "    \n",
    "    # Remove Null Quote\n",
    "    return df_clean.rename({\"RET\":\"Ret\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "693324b7-3ec6-45b7-8c5c-35383805779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算市值與上一期市值以計算市值權重(避免look-ahead bias)\n",
    "def get_mkt_cap(df: pd.DataFrame):\n",
    "    df_mkt_cap = df.copy()\n",
    "    # Calculate Market Cap for each stock \n",
    "    df_mkt_cap.loc[:, \"mkt_cap\"]= np.abs(df_mkt_cap.PRC) * df_mkt_cap.SHROUT / 1e3\n",
    "    \n",
    "    # Calculate Lagged Market Cap for weight calculations\n",
    "    def get_lagged_mkt_cap(df):\n",
    "        df = df.assign(\n",
    "            month_diff = lambda x: (x.date.dt.year - x.date.shift(1).dt.year) * 12 + x.date.dt.month - x.date.shift(1).dt.month,\n",
    "            lag_Mkt_Cap = lambda x: (x.mkt_cap.shift(1) * (x.month_diff==1))\n",
    "        ).drop(\"month_diff\", axis=1)\n",
    "        return df\n",
    "    \n",
    "    df_mkt_cap = df_mkt_cap.groupby([\"PERMNO\"]).apply(get_lagged_mkt_cap, include_groups=False).reset_index().drop(\"level_1\", axis=1)\n",
    "    return df_mkt_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc462812-6194-4fd5-9f76-c8a54d9a864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算動能排序來分組\n",
    "def get_ranking_returns(df: pd.DataFrame):\n",
    "    df.sort_values([\"PERMNO\", \"date\"], inplace=True)\n",
    "    unique_date = df.sort_values(\"date\").date.unique()\n",
    "    date = df.date\n",
    "    # Check constraints\n",
    "    df = df.assign(\n",
    "        valid_prc = lambda x: x.PRC.notna(),\n",
    "        # Floor return to avoid errors when converting to log returns\n",
    "        floor_Ret = lambda x: np.maximum(x.Ret, -0.99999),\n",
    "        log_Ret = lambda x: np.log1p(x.floor_Ret),\n",
    "        valid_shr = lambda x: x.SHROUT.notna(),\n",
    "        valid_mktcap = lambda x: x.lag_Mkt_Cap.notna() & x.lag_Mkt_Cap > 0,\n",
    "        valid_formation = lambda x: x.valid_prc & x.valid_shr & x.valid_mktcap\n",
    "    )\n",
    "    res = []\n",
    "    \n",
    "    for start, ret_start, ret_end, end in zip(unique_date, unique_date[1:], unique_date[11:], unique_date[13:]):\n",
    "        df_filtered = df.loc[(date>=start)&(date<=end)]\n",
    "\n",
    "        # Filter out all ineligible stocks based on the requirements\n",
    "        m_1 = (df_filtered.date==start)&(df_filtered.valid_prc)\n",
    "        eligible_permno_1 = set(df_filtered.loc[m_1, \"PERMNO\"])\n",
    "        \n",
    "        m_2 = (df_filtered.date==ret_end)&(df_filtered.valid_ret)\n",
    "        eligible_permno_2 = set(df_filtered.loc[m_2, \"PERMNO\"])\n",
    "        \n",
    "        m_3 = (df_filtered.date==end)&(df_filtered.valid_formation)\n",
    "        eligible_permno_3 = set(df_filtered.loc[m_3, \"PERMNO\"])\n",
    "        \n",
    "        eligible_permno_4 = df_filtered.loc[(df_filtered.date>=ret_start)&(df_filtered.date<=ret_end)].groupby([\"PERMNO\"])['valid_ret'].sum().ge(8).reset_index()\n",
    "        eligible_permno_4 = set(eligible_permno_4.loc[eligible_permno_4.valid_ret, \"PERMNO\"])\n",
    "        \n",
    "        eligible_permno = eligible_permno_1 & eligible_permno_2 & eligible_permno_3 & eligible_permno_4\n",
    "        ret_t = df_filtered[(df_filtered.date>=ret_start) & (df_filtered.PERMNO.isin(eligible_permno))]\n",
    "\n",
    "        cum_rets = ret_t[ret_t.date<=ret_end].groupby([\"PERMNO\"])[\"log_Ret\"].sum().rename(\"Ranking_Ret\")\n",
    "\n",
    "        ret_t  = pd.merge(ret_t.loc[ret_t.date==end, :], cum_rets, how=\"inner\", left_on=[\"PERMNO\"], right_index=True)\n",
    "        res.append(ret_t)\n",
    "        \n",
    "    res = pd.concat(res) \n",
    "    res = res.assign(\n",
    "            Year = res.date.dt.year,\n",
    "            Month = res.date.dt.month\n",
    "        ).drop(\"date\", axis=1)\n",
    "    \n",
    "    \n",
    "    return res.reset_index().loc[:, [\"Year\", \"Month\", \"PERMNO\", \"EXCHCD\", \"lag_Mkt_Cap\", \"Ret\", \"Ranking_Ret\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54a85208-7e27-4ca8-ac40-ce88f0bc48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_momentum_data(CRSP_Stocks: pd.DataFrame):\n",
    "    CRSP_Stocks_clean = clean_CRSP_Stocks(CRSP_Stocks)\n",
    "    CRSP_Stocks_mkt_cap = get_mkt_cap(CRSP_Stocks_clean)\n",
    "    CRSP_Stocks_Momentum = get_ranking_returns(CRSP_Stocks_mkt_cap)\n",
    "    \n",
    "    return CRSP_Stocks_Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a634b499-bc7c-43a6-92bb-a2f0b3d286fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分組(paper vs French)\n",
    "def assign_momentum_deciles(CRSP_Stocks_Momentum: pd.DataFrame):\n",
    "    def get_decile(x):\n",
    "        # Daniel & Mokskowitz\n",
    "        # Get Breakpoints based on all Stocks\n",
    "        x.loc[:, \"DM_decile\"] = pd.qcut(x.Ranking_Ret, 10, labels=np.arange(1, 11, 1), precision=5).astype(int)\n",
    "        # Kenneth R. French (Below code are from Momentum_weekly_FULL_CODE.ipynb provided by the professor)\n",
    "        # Get Breakpoints based on only NYSE Stocks (Exchange Code = 1)\n",
    "        nyse_breakpoint = pd.qcut(x.loc[x.EXCHCD==1, \"Ranking_Ret\"], 10, retbins=True, labels=False)[1]\n",
    "        nyse_breakpoint[0], nyse_breakpoint[10] = -np.inf, np.inf\n",
    "        x.loc[:, \"KRF_decile\"] = pd.cut(x.Ranking_Ret, bins=nyse_breakpoint, labels=np.arange(1, 11, 1), precision=5).astype(int)\n",
    "        return x\n",
    "    \n",
    "    CRSP_Stocks_Momentum_decile = CRSP_Stocks_Momentum.groupby([\"Year\", \"Month\"]).apply(get_decile, include_groups=False).reset_index()\n",
    "    return CRSP_Stocks_Momentum_decile.loc[:, [\"Year\", \"Month\", \"PERMNO\", \"lag_Mkt_Cap\", \"Ret\", \"DM_decile\", \"KRF_decile\", \"EXCHCD\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7b47e67-d520-4610-bd7a-88538b49e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#清理Fama-French資料\n",
    "def clean_FF_mkt(df: pd.DataFrame):\n",
    "    df_clean = df.copy()\n",
    "    df_clean = df_clean.assign(\n",
    "        Date = lambda x: pd.to_datetime(x.iloc[:, 0], format='%Y%m'),\n",
    "        Year = lambda x: x.Date.dt.year,\n",
    "        Month = lambda x: x.Date.dt.month,\n",
    "    )\n",
    "    df_clean.loc[:, [\"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]] = df_clean.loc[:, [\"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]]/100\n",
    "    # Rearranging and dropping the columns\n",
    "    df_clean = df_clean.loc[:, [\"Year\", \"Month\", \"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]]\n",
    "    df_clean.columns = [\"Year\", \"Month\", \"Market_minus_Rf\", \"SMB\", \"HML\", \"Rf\"]\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34d14333-aecf-4308-9cae-cbc91bf04fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算每個月時每個decile投資組合的市值加權報酬率\n",
    "def calculate_portfolio_returns(CRSP_Stocks_Momentum_decile: pd.DataFrame, FF_mkt: pd.DataFrame):\n",
    "    def get_vw_rets(x):\n",
    "        x.loc[:, \"total_mv\"] = x.lag_Mkt_Cap.sum()\n",
    "        x.loc[:, \"Port_Ret\"] = np.sum(x.Ret * x.lag_Mkt_Cap) / x.total_mv\n",
    "        return x[[\"Port_Ret\"]].iloc[-1]\n",
    "    \n",
    "    # Get Value-weighted return for Daniel & Mokskowitz Portfolio\n",
    "    DM_ret = CRSP_Stocks_Momentum_decile.groupby([\"Year\", \"Month\", \"DM_decile\"]).apply(get_vw_rets, include_groups=False).reset_index()\n",
    "    DM_ret = DM_ret.loc[:, [\"Year\", \"Month\", \"DM_decile\", \"Port_Ret\"]].rename({\"DM_decile\":\"decile\", \"Port_Ret\":\"DM_Ret\"}, axis=1)\n",
    "    \n",
    "    # Get Value-weighted return for Kenneth R. French\n",
    "    KRF_ret = CRSP_Stocks_Momentum_decile.groupby([\"Year\", \"Month\", \"KRF_decile\"]).apply(get_vw_rets, include_groups=False).reset_index()\n",
    "    KRF_ret = KRF_ret.loc[:, [\"Year\", \"Month\", \"KRF_decile\", \"Port_Ret\"]].rename({\"KRF_decile\":\"decile\", \"Port_Ret\":\"KRF_Ret\"}, axis=1)\n",
    "    \n",
    "    # Extract Rf rate for each month\n",
    "    Rf = FF_mkt.loc[:, [\"Year\", \"Month\", \"Rf\"]]\n",
    "    Rf.loc[:, \"Rf\"] = Rf.loc[:, \"Rf\"]\n",
    "    \n",
    "    # Merge value returns for both portfolio and risk free rate\n",
    "    CRSP_Stocks_Momentum_returns = pd.merge(DM_ret, KRF_ret, how=\"inner\", on=[\"Year\", \"Month\", \"decile\"])\n",
    "    CRSP_Stocks_Momentum_returns = pd.merge(CRSP_Stocks_Momentum_returns, Rf, how=\"left\", on=[\"Year\", \"Month\"])\n",
    "    \n",
    "    return CRSP_Stocks_Momentum_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d66f7b1a-4020-4cd1-bc3c-076ba79ad893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#將paper提供的報酬檔案做清理與標準化, to compare\n",
    "def clean_DM_ret(df: pd.DataFrame):\n",
    "    df_clean = df.copy()\n",
    "    df_clean.columns = [\"date\", \"decile\", \"DM_Ret\", \"_\", \"__\"]\n",
    "    df_clean = df_clean.assign(\n",
    "        Date = lambda x: pd.to_datetime(x.iloc[:, 0], format='%Y%m%d'),\n",
    "        Year = lambda x: x.Date.dt.year,\n",
    "        Month = lambda x: x.Date.dt.month,\n",
    "    )\n",
    "    # Rearranging and dropping the columns\n",
    "    return df_clean.loc[:, [\"Year\", \"Month\", \"decile\", \"DM_Ret\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58c8b0f9-2f99-40fb-9aaa-6004c9487cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算每個月winner-loser的報酬率\n",
    "def get_wml(df: pd.DataFrame, col: str):\n",
    "        # Pivot the dataframe\n",
    "        pivot = df.pivot(index=[\"Year\",\"Month\"], columns=\"decile\", values=col)\n",
    "        # Derive WML returns\n",
    "        pivot.loc[:, \"WML\"] = pivot[10] - pivot[1]\n",
    "        # Restore the original format\n",
    "        pivot = pivot.reset_index().melt([\"Year\",\"Month\"], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"WML\"], \"decile\", col)\n",
    "        return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc59a41b-e75e-405f-9fbd-0b61721af6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算我自己複製的DM分組中每個Decile的年度化報酬、波動度、sharpe ratio、偏態以及和原始DM檔的相關性\n",
    "#驗證有沒有高度一致及看風險調整後表現\n",
    "def generate_dm_summary_stats(CRSP_Stocks_Momentum_returns: pd.DataFrame, DM_returns: pd.DataFrame):\n",
    "    \n",
    "    def get_summary_stats(x: pd.Series):\n",
    "        # Annualized Mean\n",
    "        ann_mean = x.DM_Ret_replica.mean()*12\n",
    "        # Standard Deviation\n",
    "        ann_std = x.DM_Ret_replica.std()*np.sqrt(12)\n",
    "        # Sharpe Ratio\n",
    "        sr = ann_mean/ann_std\n",
    "        # Skewness\n",
    "        skewness = np.log(x.DM_Ret_replica+x.Rf+1).skew()\n",
    "        # correlation\n",
    "        corr = x.loc[:, [\"DM_Ret_replica\", \"DM_Ret_true\"]].corr().loc[\"DM_Ret_replica\", \"DM_Ret_true\"]\n",
    "        return [round(ann_mean*100, 2), round(ann_std*100, 2), round(sr, 2), round(skewness, 2), round(corr, 4)]\n",
    "    \n",
    "    df = CRSP_Stocks_Momentum_returns.copy()\n",
    "    rf = CRSP_Stocks_Momentum_returns.loc[:, [\"Year\", \"Month\", \"Rf\"]]\n",
    "    \n",
    "    rf = rf.groupby([\"Year\", \"Month\"])[\"Rf\"].first().reset_index()\n",
    "    df = get_wml(df, \"DM_Ret\")\n",
    "    \n",
    "    df = pd.merge(df, rf, how=\"left\", on=[\"Year\", \"Month\"])\n",
    "    DM_returns = get_wml(DM_returns, \"DM_Ret\")\n",
    "    \n",
    "    df = pd.merge(df, DM_returns, how=\"left\", left_on=[\"Year\", \"Month\", \"decile\"], right_on=[\"Year\", \"Month\", \"decile\"], suffixes=(\"_replica\", \"_true\"))\n",
    "    \n",
    "    df.loc[df.decile!=\"WML\", \"DM_Ret_replica\"] = df.loc[df.decile!=\"WML\", \"DM_Ret_replica\"] - df.loc[df.decile!=\"WML\", \"Rf\"]\n",
    "    df.loc[df.decile!=\"WML\", \"DM_Ret_true\"] = df.loc[df.decile!=\"WML\", \"DM_Ret_true\"] - df.loc[df.decile!=\"WML\", \"Rf\"]\n",
    "    \n",
    "    res_index = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"WML\"]\n",
    "    res = [get_summary_stats(df.loc[df.decile==decile, :]) for decile in res_index]\n",
    "    res_col = [\"Excess Return\", \"Volatility\", \"Sharpe Ratio\", \"Skewness\", \"corr w/ original\"]\n",
    "    res = pd.DataFrame(res, index=res_index, columns=res_col)\n",
    "    return res.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "584f2e6b-2c95-452d-ab6c-57bbc1472ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#整理KRF decile報酬\n",
    "def clean_KRF_ret(df: pd.DataFrame):\n",
    "    df_clean = df.copy()\n",
    "    df_clean.columns = np.arange(1, 11, 1)\n",
    "    df_clean = df_clean.assign(\n",
    "        Date = lambda x: pd.to_datetime(x.index, format='%Y%m'),\n",
    "        Year = lambda x: x.Date.dt.year,\n",
    "        Month = lambda x: x.Date.dt.month,\n",
    "    ).reset_index(drop=True).drop(\"Date\", axis=1)\n",
    "   \n",
    "    # Melt the columns to row\n",
    "    df_clean = df_clean.melt([\"Year\",\"Month\"], np.arange(1, 11, 1), \"decile\", \"KRF_Ret\")\n",
    "    df_clean.loc[:, \"KRF_Ret\"] = df_clean.loc[:, \"KRF_Ret\"]/100\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60962e58-957b-4544-bfbf-066e78d49f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算我複製出來的KRF decile投資組合的指標\n",
    "def generate_krf_summary_stats(CRSP_Stocks_Momentum_returns: pd.DataFrame, KRF_returns: pd.DataFrame):\n",
    "    def get_summary_stats(x: pd.Series):\n",
    "        # Annualized Mean\n",
    "        ann_mean = x.KRF_Ret_replica.mean()*12\n",
    "        # Standard Deviation\n",
    "        ann_std = x.KRF_Ret_replica.std()*np.sqrt(12)\n",
    "        # Sharpe Ratio\n",
    "        sr = ann_mean/ann_std\n",
    "        # Skewness\n",
    "        skewness = np.log(x.KRF_Ret_replica+x.Rf+1).skew()\n",
    "        # correlation\n",
    "        corr = x.loc[:, [\"KRF_Ret_replica\", \"KRF_Ret_true\"]].corr().loc[\"KRF_Ret_replica\", \"KRF_Ret_true\"]\n",
    "        return [round(ann_mean,4)*100, round(ann_std,4)*100, round(sr, 2), round(skewness, 2), round(corr, 4)]\n",
    "    \n",
    "    df = CRSP_Stocks_Momentum_returns.copy()\n",
    "    rf = CRSP_Stocks_Momentum_returns.loc[:, [\"Year\", \"Month\", \"Rf\"]]\n",
    "    \n",
    "    rf = rf.groupby([\"Year\", \"Month\"])[\"Rf\"].first().reset_index()\n",
    "    df = get_wml(df, \"KRF_Ret\")\n",
    "    \n",
    "    df = pd.merge(df, rf, how=\"left\", on=[\"Year\", \"Month\"])\n",
    "    KRF_returns = get_wml(KRF_returns, \"KRF_Ret\")\n",
    "    \n",
    "    df = pd.merge(df, KRF_returns, how=\"left\", left_on=[\"Year\", \"Month\", \"decile\"], right_on=[\"Year\", \"Month\", \"decile\"], suffixes=(\"_replica\", \"_true\"))\n",
    "    \n",
    "    df.loc[df.decile!=\"WML\", \"KRF_Ret_replica\"] = df.loc[df.decile!=\"WML\", \"KRF_Ret_replica\"] - df.loc[df.decile!=\"WML\", \"Rf\"]\n",
    "    df.loc[df.decile!=\"WML\", \"KRF_Ret_true\"] = df.loc[df.decile!=\"WML\", \"KRF_Ret_true\"] - df.loc[df.decile!=\"WML\", \"Rf\"]\n",
    "    \n",
    "    res_index = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"WML\"]\n",
    "    res = [get_summary_stats(df.loc[df.decile==decile, :]) for decile in res_index]\n",
    "    res_col = [\"Excess Return\", \"Volatility\", \"Sharpe Ratio\", \"Skewness\", \"corr w/ original\"]\n",
    "    res = pd.DataFrame(res, index=res_index, columns=res_col)\n",
    "    return res.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece31ec-9971-4043-b12f-037f4629aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Question 1\n",
    "    CRSP_Stocks = pd.read_pickle('./data/CRSP.pkl')\n",
    "    CRSP_Stocks = CRSP_Stocks.rename({\"permno\":\"PERMNO\", \"exchcd\":\"EXCHCD\", \"ret\":\"RET\", \"shrcd\":\"SHRCD\", \"shrout\":\"SHROUT\", \"prc\":\"PRC\", \"dlret\":\"DLRET\"}, axis=1)\n",
    "    CRSP_Stocks = CRSP_Stocks.loc[:, [\"date\", \"PERMNO\", \"EXCHCD\", \"RET\", \"SHRCD\", \"SHROUT\", \"PRC\", \"DLRET\"]]\n",
    "    CRSP_Stocks_Momentum = prepare_momentum_data(CRSP_Stocks)\n",
    "    print(\"Sample Result for Question 1\")\n",
    "    print(CRSP_Stocks_Momentum)\n",
    "    print(\"\")\n",
    "\n",
    "    # Question 2\n",
    "    CRSP_Stocks_Momentum_decile = assign_momentum_deciles(CRSP_Stocks_Momentum)\n",
    "    print(\"Sample Result for Question 2\")\n",
    "    print(CRSP_Stocks_Momentum_decile)\n",
    "    print(\"\")\n",
    "\n",
    "    # Question 3\n",
    "    FF_mkt = pd.read_csv(\"F-F_Research_Data_Factors.CSV\", skiprows=3, nrows=1182)\n",
    "    FF_mkt = clean_FF_mkt(FF_mkt)\n",
    "    print(\"Input: Fama-French Market DataFrame (FF_mkt)\")\n",
    "    print(FF_mkt)\n",
    "    print(\"\")\n",
    "    \n",
    "    CRSP_Stocks_Momentum_returns = calculate_portfolio_returns(CRSP_Stocks_Momentum_decile, FF_mkt)\n",
    "    print(\"Sample Result for Question 3\")\n",
    "    print(CRSP_Stocks_Momentum_returns)\n",
    "    print(\"\")\n",
    "\n",
    "    # Question 4\n",
    "    DM_returns = pd.read_csv('m_m_pt_tot.txt', sep=\"\\\\s+\", header=None)\n",
    "    DM_returns = clean_DM_ret(DM_returns)\n",
    "    print(\"Input: Momentum portfolio returns from Daniel\\'s website (DM_returns)\")\n",
    "    print(DM_returns)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Sample Result for Question 4\")\n",
    "    DM_res = generate_dm_summary_stats(CRSP_Stocks_Momentum_returns, DM_returns)\n",
    "    print(DM_res)\n",
    "    print(\"\")\n",
    "\n",
    "    # Question 5\n",
    "    KRF_returns = pd.read_csv(\"10_Portfolios_Prior_12_2.csv\", skiprows=10, nrows=1176, index_col=0)\n",
    "    KRF_returns = clean_KRF_ret(KRF_returns)\n",
    "    print(\"Input: Momentum portfolio returns from French\\'s website (KRF_returns)\")\n",
    "    print(KRF_returns)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Sample Result for Question 5\")\n",
    "    KRF_res = generate_krf_summary_stats(CRSP_Stocks_Momentum_returns, KRF_returns)\n",
    "    print(KRF_res)\n",
    "    print(\"\")\n",
    "\n",
    "    # Question 6\n",
    "    wml_port_rets = get_wml(CRSP_Stocks_Momentum_returns, \"DM_Ret\").merge(get_wml(CRSP_Stocks_Momentum_returns, \"KRF_Ret\"), on=[\"Year\", \"Month\", \"decile\"])\n",
    "    wml_port_rets = wml_port_rets[wml_port_rets.decile==\"WML\"].drop([\"decile\"], axis=1)\n",
    "    wml_port_rets.loc[:, \"str_date\"] = wml_port_rets[\"Year\"].astype(str) + wml_port_rets[\"Month\"].astype(str).str.zfill(2)\n",
    "    wml_port_rets.loc[:, \"date\"] = pd.to_datetime(wml_port_rets.loc[:, \"str_date\"], format='%Y%m')\n",
    "    wml_port_rets = wml_port_rets.set_index(\"date\")\n",
    "    wml_port_rets.drop([\"Year\", \"Month\", \"str_date\"], axis=1, inplace=True)\n",
    "    wml_port_rets = np.log(wml_port_rets+1).cumsum()\n",
    "    wml_port_rets.columns = [\"DM\", \"KRF\"]\n",
    "    wml_port_rets.plot()\n",
    "    plt.title(\"Cumulative Log Returns of MOM portfolios 1929-2024\")\n",
    "    plt.show()\n",
    "\n",
    "    wml_port_rets_2010 = wml_port_rets.loc[\"2010-01-01\":]\n",
    "    wml_port_rets_2010 = wml_port_rets_2010 - wml_port_rets_2010.loc[\"2010-01-01\", :]\n",
    "    wml_port_rets_2010.plot()\n",
    "    plt.title(\"Cumulative Log Returns of MOM portfolios 2010-2024\")\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
